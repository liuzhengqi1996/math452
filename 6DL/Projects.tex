\setcounter{chapter}{-1}
\chapter{Plan }

\section{Ongoing projects}
\begin{enumerate}
\item Zhang Qian
  \begin{enumerate}
\item Oversee all the notes taking
  \item Read Chapters on SVM and KNN, try to rearrange and then
    discuss with Xu
  \end{enumerate}
\item Basic Machine Learning Theory:  Yin Pengfei and Jonathon Siegal
\item Zhao Liang
  \begin{enumerate}
  \item Stochastic and incremental gradient descent
  \end{enumerate}
\item Li Lin
  \begin{enumerate}
  \item Spectral approximation of DNN
  \end{enumerate}
\item Zheng Chunyue
  \begin{enumerate}
  \item Universal approximation theory
  \end{enumerate}
\end{enumerate}


\section{Participants}
\begin{enumerate}
\item Chen Jianhong
\item Chen Yuyan 
\item He Juncai 
\item Hong Qingguo
\item Jia Xiaodong
\item Jiang Li
\item Liang Shaobo
\item Li Lin
\item Wu Shuonan
\item Zheng Chunyue
\item Zhao Liang
\item Zhang Qian
\item Hu Junfeng
\item Wu Shaowu
\end{enumerate}

\section{Notes taking}
\begin{enumerate}
\item Basic Machine Learning Theory:  Yin Pengfei and Jonathon Siegal
\item SVM and KNN:  Zhang Qian

\item Juncai:  Re-arrange and merge materials; CNN-DNN, SGD
\item Zhao Liang:  optimization methods (chapter)
\item Xiaodong: BN, loss-functions, cross-entropy
  training-validation-test data, RL
\item Yuyan:  PCA, drop-out, audo encoder-decoder
\item Guangchun:  RNN
\item Qipin: SA, Approximation theory,
\item Qingguo: Multigrid
\item Lin:  DL for PDEs
\item Jianhong: the rest
\end{enumerate}

\section{Jiang Li's presentation on December 12}
\begin{enumerate}
\item ABCD ... matrix times matrix, ... matrix times vectors 
\item (6.59): Hessian matrix computation
\item Is ReLU really better than cosine?
\end{enumerate}

\section{Research Topics}
\subsection{Batch normalization (Xiaodong)
\hfill Notes due Monday December 11}
\begin{enumerate}
\item Implementation of classic BN: demonstrate the advantage of BN
\item Try new idea:  
\end{enumerate}

\subsection{Drop-out}
\begin{enumerate}
\item Linear problem
\item Multigrid methods
\end{enumerate}

\subsection{Simulated annealing}
\begin{enumerate}
\item Decreasing minibatch size
\item Multilevel SA method
\item Allen-Cahn model applications
\end{enumerate}

\subsection{Nonlinear Gauss-Seidel}
\subsection{Encode and decode}
\subsection{ResNet versus Multigrid}
\subsection{SGD}
\subsection{Deeplearning for PDE}
\subsection{DNN and finite elements}

\section{Adversarial networks}

\section{Distance between two images}
