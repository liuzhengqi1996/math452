# Image classification problem 

 ```{admonition} Image classification problem 
We consider a basic machine learning problem for classifying a collection of images
into k distinctive classes. As an example, we consider a two-dimensional image
which is usually represented by a tensor $x \in R^{n_0\times n_0 \times c} = R^d$
Here $n_0 \times n_0$ is the original image resolutuon and

$
c=
	\left \{
	\begin{array}[rl]{rl}
	1 & \mbox{for grayscale image},\\    
	3 & \mbox{for color image}.
	\end{array}
	\right.
$

A typical supervised machine learning problem begins with a data set (training
data)

$
\begin{aligned}
D &= \{(x_j, y_j)\}_{j=1}^N, \quad \text{and} \quad A = \{ x_1, x_2, \cdots, x_N\}  \\
A &= A_1\cup A_2\cup \cdots \cup A_k, ~A_i\cap A_j = \emptyset, \forall i \neq j
\end{aligned}$

and $y_j \in R^k$ is the label for data $x_j$, with $y_i[i]$ as the probability for $x_i$ in classes $i$ or $x_j \in A_i$.
Here for image classification problem, $y_j = e_{i_j}$, 
if $x_j \in A_{i_j}$ or we say $x_j$ has real label $i_j$.
Roughly speaking, a supervised learning problem can be thought as a data fitting
problem in a high dimensional space $R^d$. 
Namely, we need to find a mapping such that, for any $x_j \in A$
```{math}
:label: eq1
f(x_j)\approx y_j = e_{i_j} \in \mathbb R^k.
```



:::{test}
How does it look like?
:::

And here is a code block(is this readable):

```
import numpy as np
```

Check out the content pages bundled with this sample book to see more.
