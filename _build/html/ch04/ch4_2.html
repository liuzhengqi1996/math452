
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4.2 Stochastic gradient descent method and convergence theory &#8212; Math 452 Site</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="4.1 Line search and gradient descent method" href="ch4_1.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/PSU_SCI_RGB_2C.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Math 452 Site</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome to Math 452
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  contents
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch00/ch0_.html">
   Ch0 Get started: course information and preparations:
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch00/ch0_1.html">
     0.1 Course information, requirements and reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch00/ch0_2.html">
     0.2 Course background and introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch00/ch0_3.html">
     0.3 Introduction to Python and Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch01/ch1_.html">
   Ch1 Machine Learning and Image Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch01/video.html">
     Chapter 1 video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch01/ch1_1_video.html">
     1.1 A basic machine learning problem: image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch01/ch1_2_video.html">
     1.2 Image classification problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch01/ch1_3_video.html">
     1.3 Some popular data sets in image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch01/hw2.html">
     Homework 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch02/ch2_.html">
   Ch2 Linear Machine Learning Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch02/ch2_1_video.html">
     2.1 Definition of linearly separable sets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch02/ch2_2.html">
     2.2 Introduction to logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch02/ch2_3.html">
     2.3 KL divergence and cross-entropy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch02/ch2_4.html">
     2.4 Support vector machine
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch03/ch3_.html">
   Ch3 Probability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_1.html">
     3.1 Introduction to probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_2.html">
     3.2 Basic probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_3.html">
     3.3 Basic Probability Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_4.html">
     3.4 Random, Variable, Mean, Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_5.html">
     3.5 Probability interpretation of logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_6.html">
     3.6 Maximamum Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_7.html">
     3.7 Basic Statistical Learning Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_8.html">
     3.8 Classfication/ Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_9.html">
     3.9 Bayesian Approach to Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch03/ch3_10.html">
     3.10 General Covariance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch4_.html">
   Chapter 4
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="ch4_1.html">
     4.1 Line search and gradient descent method
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     4.2 Stochastic gradient descent method and convergence theory
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch04/ch4_2.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/liuzhengqi1996/math452/main?urlpath=lab/tree/ch04/ch4_2.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convergence-of-sgd">
   4.2.1 Convergence of SGD
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sgd-with-mini-batch">
   4.2.2 SGD with mini-batch
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="stochastic-gradient-descent-method-and-convergence-theory">
<h1>4.2 Stochastic gradient descent method and convergence theory<a class="headerlink" href="#stochastic-gradient-descent-method-and-convergence-theory" title="Permalink to this headline">¶</a></h1>
<p>The next optimization problem is the most common case in machine
learning.</p>
<div class="highlight-problem notranslate"><div class="highlight"><pre><span></span>
$$\label{SGDproblem}  
    \min_{x \in \mathbb{R}^n} f(x)\quad \mbox{and}\quad f(x) = \frac{1}{N} \sum_{i=1}^N f_i(x).
$$

</pre></div>
</div>
<p>One version of stochastic gradient descent (SGD) algorithm is:</p>
<div class="highlight-algorithm notranslate"><div class="highlight"><pre><span></span>**Input**: initialization $x_0$, learning rate $\eta_t$.

**For**: t = 0,1,2,$\dots$

Randomly pick $i_t \in \{1, 2, \cdots, N\}$ independently with
probability $\frac{1}{N}$ 

$$
    \label{equ:sgd-iteration}
    x_{t+1} = x_{t} - \eta_t \nabla f_{i_t}(x_t).
$$

</pre></div>
</div>
<div class="section" id="convergence-of-sgd">
<h2>4.2.1 Convergence of SGD<a class="headerlink" href="#convergence-of-sgd" title="Permalink to this headline">¶</a></h2>
<div class="highlight-theorem notranslate"><div class="highlight"><pre><span></span>Assume that each $f_i(x)$ is $\lambda$-strongly convex and
$\|\nabla f_i(x)\| \le M$ for some $M &gt;0$. If we take
$\eta_t = \frac{a}{\lambda (t+1)}$ with sufficiently large $a$ such that

$$
    \label{key}
    \|x_0 - x^*\|^2 \le \frac{a^2M^2}{(a-1)\lambda^2}
$$

then

$$
    \mathbb{E}e_{t}^2 \le \frac{a^2M^2}{(a-1)\lambda^2 (t+1)}, \quad  t\ge 1,
$$

where $e_t = \|x_t - x^*\|$.
</pre></div>
</div>
<div class="highlight-proof notranslate"><div class="highlight"><pre><span></span>*Proof.* The $L^2$ error of SGD can be written as 

$$
    \label{equ:L2SGD}
      \begin{split}
            \mathbb{E} \|x_{t+1} - x^*\|^2 &amp;\le \mathbb{E}\| x_{t} - \eta_t \nabla f_{i_t}(x_t) - x^* \|^2 \\
            &amp;\le \mathbb{E} \|x_t - x^*\|^2 
            - 2 \eta_t \mathbb{E} (\nabla f_{i_t}(x_t) \cdot (x_t - x^*)) 
            + \eta_t^2 \mathbb{E} \|\nabla f_{i_t}(x_t)\|^2 \\
            &amp; \le \mathbb{E} \|x_t - x^*\|^2 - 2 \eta_t \mathbb{E} (\nabla f (x_t) \cdot (x_t - x^*))
            + \eta_t^2 M^2 \\
            &amp; \le \mathbb{E} \|x_t - x^*\|^2 -  \eta_t \lambda \mathbb{E} \|x_t - x^*\|^2 + \eta_t^2 M^2 \\
            &amp; = (1 - \eta_t\lambda) \mathbb{E} \|x_t - x^*\|^2 + \eta_t^2 M^2
      \end{split}
$$

The third line comes from the fact that

$$
    \label{key}
    \begin{aligned}
    \mathbb{E} (\nabla f_{i_t}(x_t) \cdot (x_t - x^*))  &amp;= \mathbb{E}_{i_1i_2\cdots i_t} (\nabla f_{i_t}(x_t) \cdot (x_t - x^*)) \\
&amp;= \mathbb{E}_{i_1i_2\cdots i_{t-1}} \frac{1}{N} \sum_{i=1}^N \nabla f_i(x_t)\cdot (x_t - x^*) \\
&amp;= \mathbb{E}_{i_1i_2\cdots i_{t-1}}  \nabla f(x_t)\cdot (x_t - x^*) \\
&amp;= \mathbb{E}\nabla f(x_t)\cdot (x_t - x^*),
\end{aligned}
$$ 

and

$$
    \mathbb{E} \|\nabla f_{i_t}(x_t)\|^2 \le \mathbb{E} M^2 = M^2.
$$

Note when $t=0$, we have 

$$
    \label{key}
    \mathbb{E} e_0^2 = \|x_0 - x^*\|^2 \le \frac{a^2M^2}{(a-1)\lambda},
$$

based on the assumption.

In the case of SDG, by the inductive hypothesis, 

$$
    \begin{split}
            \mathbb{E}e_{t+1}^2 &amp; \le (1 - \eta_t\lambda)\mathbb{E}e_{t}^2  + \eta_t^2 M^2\\
            &amp;\le  (1 - \frac{a}{t+1}) \frac{a^2M^2}{(a-1)\lambda^2 (t+1)} + \frac{a^2M^2}{\lambda^2 (t+1)^2} \\
            &amp; \le \frac{a^2M^2}{(a-1)\lambda^2} \frac{1}{(t+1)^2}(t+1 -a + a-1) \\
            &amp; = \frac{a^2M^2}{(a-1)\lambda^2} \frac{t}{(t+1)^2} \\
            &amp; \le \frac{a^2M^2}{(a-1)\lambda^2(t+2)}. \quad \left(\frac{t}{(t+1)^2} \le \frac{1}{t+2}\right),
      \end{split}
$$

which completes the proof. ◻
</pre></div>
</div>
</div>
<div class="section" id="sgd-with-mini-batch">
<h2>4.2.2 SGD with mini-batch<a class="headerlink" href="#sgd-with-mini-batch" title="Permalink to this headline">¶</a></h2>
<p>Firstly, we will introduce a natural extended version of the SGD
discussed above with introducing mini-batch.</p>
<div class="highlight-algorithm notranslate"><div class="highlight"><pre><span></span>**Input**: initialization $x_0$, learning rate $\eta_t$.

**For**: t = 0,1,2,$\dots$

::: center
Randomly pick $B_t \subset \{1, 2, \cdots, N\}$ independently with
probability $\frac{m!(N-m)!}{N!}$\
and $\# B_t = m$.
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[
    \label{equ:sgd-iteration}
    x_{t+1} = x_{t} - \eta_t g_t(x_t).
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
    g_{t}(x_t) = \frac{1}{m} \sum_{i \in B_{t}}  \nabla f_i(x_t)
\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
Now we introduce the SGD algorithm with mini-batch without replacement
which is the most commonly used version of SGD in machine learning.

::: algorithm
**Input**: learning rate $\eta_k$, mini-batch size $m$, parameter
initialization $x_{0}$ and denote $M = \lceil \frac{N}{m} \rceil$.

**For** Epoch $k = 1,2,\dots$

::: center
Randomly pick $B_t \subset \{1, 2, \cdots, N \}$ without replacement\
with $\# B_t = m$ for $t = 1,2,\cdots,M$.
</pre></div>
</div>
<p>mini-batch <span class="math notranslate nohighlight">\(t = 1:M\)</span></p>
<p>Compute the gradient on <span class="math notranslate nohighlight">\(B_{t}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
    g_{t}(x) = \frac{1}{m} \sum_{i \in B_{t}}  \nabla f_i(x)
\]</div>
<p>Update <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="math notranslate nohighlight">
\[
    x  \leftarrow  x - \eta_k g_t(x),
\]</div>
<p><strong>EndFor</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
To \&quot;randomly pick $B_i \subset \{1, 2, \cdots, N \}$ without
replacement with $\# B_i = m$ for $i = 1,2,\cdots,t$&quot;, we usually just
randomly shuffle the index set first and then consecutively pick every
$m$ elements in the shuffled index set. That is the reason why we would
like to call the algorithm as shuffled SGD while this is the mostly used
version of SGD in machine learning.

::: remark
Let us recall a general machine learning loss function 

$$
    \label{key}
    L(\theta) = \frac{1}{N}\sum_{i=1}^N \ell(h(X_i; \theta), Y_i),
$$

where
$\{(X_i, Y_i)\}_{i=1}^N$ correspond to these data pairs. For example,
$\ell(\cdot, \cdot)$ takes cross-entropy and
$h(x; \theta) = \bm p(x;\theta)$ as we discussed in Section
[\[sec:LR\]](#sec:LR){reference-type=&quot;ref&quot; reference=&quot;sec:LR&quot;}. Thus, we
have the following corresponding relation

$$
    f(x) \leftrightsquigarrow L(\theta), \quad
    f_i(x) \leftrightsquigarrow \ell(h(X_i; \theta), Y_i).
$$
    
</pre></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch04"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="ch4_1.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">4.1 Line search and gradient descent method</p>
            </div>
        </a>
    </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Department of Mathematics, Penn State University Park<br/>
        
            &copy; Copyright The Pennsylvania State University, 2021. This material is not licensed for resale.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-206078372-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>