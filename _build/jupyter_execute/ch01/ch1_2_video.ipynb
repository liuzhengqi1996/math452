{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe8efc7",
   "metadata": {},
   "source": [
    "# Image classification problem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafbb57",
   "metadata": {},
   "source": [
    "## Image classification problem \n",
    "We consider a basic machine learning problem for classifying a collection of images\n",
    "into k distinctive classes. As an example, we consider a two-dimensional image\n",
    "which is usually represented by a tensor $x \\in R^{n_0\\times n_0 \\times c} = R^d$\n",
    "Here $n_0 \\times n_0$ is the original image resolutuon and\n",
    "\n",
    "$\n",
    "c=\n",
    "\t\\left \\{\n",
    "\t\\begin{array}[rl]{rl}\n",
    "\t1 & \\mbox{for grayscale image},\\\\    \n",
    "\t3 & \\mbox{for color image}.\n",
    "\t\\end{array}\n",
    "\t\\right.\n",
    "$\n",
    "\n",
    "A typical supervised machine learning problem begins with a data set (training\n",
    "data)\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "D &= \\{(x_j, y_j)\\}_{j=1}^N, \\quad \\text{and} \\quad A = \\{ x_1, x_2, \\cdots, x_N\\}  \\\\\n",
    "A &= A_1\\cup A_2\\cup \\cdots \\cup A_k, ~A_i\\cap A_j = \\emptyset, \\forall i \\neq j\n",
    "\\end{aligned}\n",
    "$\n",
    "and $y_j \\in R^k$ is the label for data $x_j$, with $y_i[i]$ as the probability for $x_i$ in classes $i$ or $x_j \\in A_i$.\n",
    "Here for image classification problem, $y_j = e_{i_j}$, \n",
    "if $x_j \\in A_{i_j}$ or we say $x_j$ has real label $i_j$.\n",
    "Roughly speaking, a supervised learning problem can be thought as a data fitting\n",
    "problem in a high dimensional space $R^d$. \n",
    "Namely, we need to find a mapping such that, for any $x_j \\in A$\n",
    "$\n",
    "f(x_j)\\approx y_j = e_{i_j} \\in \\mathbb R^k.\n",
    "$\n",
    "\n",
    "\n",
    "for data $x_j \\in A$. For general setting above, we use a probatillistic model for understanding the output $f(x) \\in R^k$ as a discrete distribution on $\\{1,\\cdots ,k\\}$,\n",
    "with $[f(x)]_{i}$ as the probability for x in the class i, namely\n",
    "$\n",
    "0 \\leq [f(x)]_i \\leq 1\n",
    "$, \n",
    "$\n",
    "\\sum_{i=1}^{k}[f(x)]_{i} =1\n",
    "$.\n",
    "At last, we finish our model with a simple strategy to choose \n",
    "$\n",
    "argmax_i\\{ [f(x)]_i :  i = 1:k\\}\n",
    "$\n",
    "as the label for a test data $x$, which ideally is close to . The remaining key issue is the construction of the classification mapping $f$.\n",
    "Generally speaking, there will be a test set\n",
    "$T = \\{(x_j,y_j)\\}_{j=1}^{M}$,\n",
    "with the same dimension of training data $D$, but is not known before we finish the\n",
    "training process. That is to say, we can use this test data $T$ to verify the performance\n",
    "of trained model $f$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c740c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}